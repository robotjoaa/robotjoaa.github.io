# Methods

## Algorithms

  Both LISA and SkillDiffuser aims to learn language conditioned policy with generalized behavior in diverse range of tasks from the fixed offline dataset. We endeavored to apply both work as a baseline in our project. 

### [LISA](https://arxiv.org/pdf/2203.00054)

  LISA had introduced method that could learn to hierarchically plan in language conditioned tasks
by utilizing high-level skill planning and low-level skill learning through decision transformer architecture. It was evaluated in both BabyAI and LOReL Sawyer benchmark, reporting human interpretable skill abstraction and generalized performance on unseen language instructions.

![Untitled](Methods%20257e2e4c83cd4fb68cbff295668c1555/Untitled.png)

### [SkillDiffuser](https://skilldiffuser.github.io/)

  Based on the LISA, SkillDiffuser introduced with better general capability by utilizing diffusion model to generate states and inverse dynamic model to infer action from the generated states. It has reported improved performance over LISA including LOReL Sawyer environment with composed and unseen tasks.

![Untitled](Methods%20257e2e4c83cd4fb68cbff295668c1555/Untitled%201.png)

Compared to pseudo code of LISA, they have identical approach of leveraging offline trajectories as a dataset with a language instruction. They sample skills every H steps from the skill predictor and vector quantization applied as an information bottleneck. This enables robust learning of skills. 

Difference between two methods are : LISA predficts action from [Decision Transformer](https://arxiv.org/abs/2106.01345) conditioned by skill embedding z. However, SkillDiffuser predicts states with diffusion model conditioned with the skill embedding, output of the skill MLP lamda. Skill MLP is used to align skill features with denoising model. Then inverse dynamics model is applied to predict actions. 

In conclusion, LISA have loss term of vector quantization loss and the behavior cloning loss combined. SkillDiffuser have separate objective of 1) vector quantization loss and diffusion loss  and 2) loss of inverse dynamics model.

## Benchmarks

### [BabyAI](https://github.com/mila-iqia/babyai)

![[Red triangle is agent, gray area is the partial observation](https://arxiv.org/pdf/1810.08272#page=5.32) ](Methods%20257e2e4c83cd4fb68cbff295668c1555/Untitled%202.png)

[Red triangle is agent, gray area is the partial observation](https://arxiv.org/pdf/1810.08272#page=5.32) 

![[BabyAI levels and the required competencies](https://arxiv.org/pdf/1810.08272)](Methods%20257e2e4c83cd4fb68cbff295668c1555/Untitled%203.png)

[BabyAI levels and the required competencies](https://arxiv.org/pdf/1810.08272)

  For long horizon composed tasks, as it is done in LISA, we conducted experiment on GoToSeq, SynthSeq, BossLevel. For dataset generation, we only considered GoToSeq environment which doesn‚Äôt have blocked path, locked door and subgoal of only ‚Äòexplore‚Äô and ‚Äògoto‚Äô is required. 

  We considered that it could be less straightforward to infer from the BabyAI environment than LOReL, since it requires long horizon reasoning including locked door and moving obstacles. How to deal with failure cases are also important to solve these environment in less time steps, without falling into endless loop of exploration. 

### [LOReL](https://github.com/suraj-nair-1/lorel)

![LOReL Sawyer robot arm manipulating table top objects](Methods%20257e2e4c83cd4fb68cbff295668c1555/Untitled%204.png)

LOReL Sawyer robot arm manipulating table top objects

![[LOReL task description, it includes language instruction with/without seen words for language ability evaluation.](https://arxiv.org/pdf/2312.11598)](Methods%20257e2e4c83cd4fb68cbff295668c1555/Untitled%205.png)

[LOReL task description, it includes language instruction with/without seen words for language ability evaluation.](https://arxiv.org/pdf/2312.11598)

  Original tasks of LOReL only includes one tasks in the above table. To create long horizontal tasks, in the SkillDiffuser paper, it extended the instructions and episode time limits, by composing the language instructions. 

![[Instructions of LOReL composition tasks.](https://arxiv.org/pdf/2312.11598)](Methods%20257e2e4c83cd4fb68cbff295668c1555/Untitled%206.png)

[Instructions of LOReL composition tasks.](https://arxiv.org/pdf/2312.11598)

## Vision Language Models, [LLaVA](https://github.com/haotian-liu/LLaVA)

As we explained in the motivation section, pre-trained LLaVA, especially LLaVA-1.5v-7b base model was used.  One of our novelty comes from introducing pipeline of data augmentation using VLM to these environments. Compared to semi-supervised learning method applied into DIAL, our method relies heavily on human bias rather supervised method. LLaVA applies **visual** **instruction tuning** method which uses image, question pair and using answers from GPT-4 as the ground truth. 

[Low-Rank Adaptation (LoRA)](https://arxiv.org/pdf/2106.09685) was applied as a parameter efficient finetuning. We tried both [QLoRA](https://arxiv.org/pdf/2305.14314)(Quantized LoRA) and LoRA but there were no significant difference found during training.

![[Key difference between LoRA and QLoRA](https://medium.com/@sujathamudadla1213/difference-between-qlora-and-lora-for-fine-tuning-llms-0ea35a195535)](Methods%20257e2e4c83cd4fb68cbff295668c1555/Untitled%207.png)

[Key difference between LoRA and QLoRA](https://medium.com/@sujathamudadla1213/difference-between-qlora-and-lora-for-fine-tuning-llms-0ea35a195535)

**We would like to mention that our purpose of this project is to validate whether our hypothesis of utilizing VLMs for sub-goal generation in hierarchical imitation learning can facilitate better training. [We strongly referred to this article for fine-tuning.](https://wandb.ai/byyoung3/ml-news/reports/How-to-Fine-Tune-LLaVA-on-a-Custom-Dataset--Vmlldzo2NjUwNTc1)**

## So, what is your plan?

**Our plan for the project changed over time from our first proposal due to computation, time constraints and most importantly, misunderstandings.** 

We originally planned to evaluate in the sub-tasks annotated dataset augmented with the VLM with the LISA and SkillDiffuser for comparison, but due to intrinsic problem in the architecture we changed our direction to focus on **whether fine-tuned VLM can be used for sub-goal generation.** 

[üè† Home](../Subgoal%20generation%20with%20Vision%20Language%20Models%20for%2071dadafcdb46425d9f40acbb7b606c42.md)

[‚áí Results](Results%20eb542b8b5ec840bb872b245719228ef3.md)